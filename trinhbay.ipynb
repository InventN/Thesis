{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmTl2kDcG3To"
      },
      "source": [
        "### Để chạy file notebook. Để file này vào chung với thư mục datasets -> chọn thời gian chạy-> chạy tất cả. Có thể đổi các tập huấn luyện từ u1.base thành u2-u5.base và u1. test thành u2.test-u5.test để kiểm tra độ đo của mô hình . Notebook được thực hiện và chạy trên môi trường google colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDwzXkmPpE-f"
      },
      "source": [
        "## 1. Import Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qCJBm2aQcx1n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import itertools\n",
        "import collections\n",
        "import itertools\n",
        "import math\n",
        "import scipy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B45nv9RpN2WD"
      },
      "source": [
        "## 2. Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9gUX4U0qmv75"
      },
      "outputs": [],
      "source": [
        "# processing and lod data\n",
        "def load_data(dataPath):\n",
        "    df = pd.read_csv(dataPath + 'u1.base',\n",
        "                     sep='\\\\t',\n",
        "                     engine='python',\n",
        "                     names=['UID', 'MID', 'rate', 'time'])\n",
        "    df_user = pd.read_csv(dataPath + 'u.user',\n",
        "                          sep='\\\\|',\n",
        "                          engine='python',\n",
        "                          names=['UID', 'age', 'gender', 'job', 'zip'])\n",
        "\n",
        "    df_user = convert_categorical(df_user, 'job')\n",
        "    df_user = convert_categorical(df_user, 'gender')\n",
        "    df_user['bin'] = pd.cut(df_user['age'], [0, 10, 20, 30, 40, 50, 100],\n",
        "                            labels=['1', '2', '3', '4', '5', '6'])\n",
        "    df_user['age'] = df_user['bin']\n",
        "\n",
        "    df_user = df_user.drop(columns='bin')\n",
        "    df_user = convert_categorical(df_user, 'age')\n",
        "    df_user = df_user.drop(columns='zip')\n",
        "    return df, df_user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "z8Hc5yXSY5mv"
      },
      "outputs": [],
      "source": [
        "# OneHotEncoder label\n",
        "def convert_categorical(df_X, _X):\n",
        "    values = np.array(df_X[_X])\n",
        "    # integer encode\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(values)\n",
        "    # binary encode\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "    df_X = df_X.drop(columns=_X)\n",
        "    for j in range(integer_encoded.max() + 1):\n",
        "        df_X.insert(loc=j + 1,\n",
        "                    column=str(_X) + str(j + 1),\n",
        "                    value=onehot_encoded[:, j])\n",
        "    return df_X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47jj0w97ZKnl"
      },
      "source": [
        "## 3. Extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "XCLZcYj9ZVUc"
      },
      "outputs": [],
      "source": [
        "# Build graph\n",
        "def train_model(df, df_user):\n",
        "    alpha_coefs = [0.01]\n",
        "\n",
        "    for alpha_coef in alpha_coefs:\n",
        "        pairs = []\n",
        "        grouped = df.groupby(['MID', 'rate'])\n",
        "\n",
        "        for key, group in grouped:\n",
        "            pairs.extend(list(itertools.combinations(group['UID'], 2)))\n",
        "\n",
        "        counter = Counter(pairs)\n",
        "        alpha = alpha_coef * 1682  # param*i_no\n",
        "        edge_list = map(\n",
        "            list,\n",
        "            Counter(el for el in counter.elements()\n",
        "                    if counter[el] >= alpha).keys())\n",
        "        G = nx.Graph()\n",
        "\n",
        "        for el in edge_list:\n",
        "            G.add_edge(el[0], el[1], weight=1)\n",
        "\n",
        "        #plt.figure(figsize=(6, 6))\n",
        "        #plt.figure(figsize = (15,10))\n",
        "        #pos = nx.kamada_kawai_layout(G)\n",
        "        #node_options = {\"node_color\": \"black\", \"node_size\" :30}\n",
        "        #edge_options = {\"width\":.50, \"alpha\" : .5 , \"edge_color\" : \"black\"}\n",
        "        #nx.draw_networkx_nodes(G, pos, **node_options)\n",
        "        #nx.draw_networkx_edges(G, pos, **edge_options)\n",
        "        #plt.show()\\\\u2.test\n",
        "\n",
        "        pr = nx.pagerank(G.to_directed())\n",
        "        df_user['PR'] = df_user['UID'].map(pr)\n",
        "        df_user['PR'] /= float(df_user['PR'].max())\n",
        "        dc = nx.degree_centrality(G)\n",
        "        df_user['CD'] = df_user['UID'].map(dc)\n",
        "        df_user['CD'] /= float(df_user['CD'].max())\n",
        "        cc = nx.closeness_centrality(G)\n",
        "        df_user['CC'] = df_user['UID'].map(cc)\n",
        "        df_user['CC'] /= float(df_user['CC'].max())\n",
        "        bc = nx.betweenness_centrality(G)\n",
        "        df_user['CB'] = df_user['UID'].map(bc)\n",
        "        df_user['CB'] /= float(df_user['CB'].max())\n",
        "        lc = nx.load_centrality(G)\n",
        "        df_user['LC'] = df_user['UID'].map(lc)\n",
        "        df_user['LC'] /= float(df_user['LC'].max())\n",
        "        nd = nx.average_neighbor_degree(G, weight='weight')\n",
        "        df_user['AND'] = df_user['UID'].map(nd)\n",
        "        df_user['AND'] /= float(df_user['AND'].max())\n",
        "        X_train = df_user.loc[:, df_user.columns[1:]]\n",
        "        X_train.fillna(0, inplace=True)\n",
        "        X_train.to_pickle(\"data100k/x_train_alpha(\" + str(alpha_coef) +\n",
        "                          \").pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGKzXV0YaMAq"
      },
      "source": [
        "## 4. Load Data Users(df_user), Ratings(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji5HZi3-aLKU",
        "outputId": "9fd32c94-fda8-41ae-fc21-d10efae61e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataPath = 'datasets/ml-100k/'\n",
        "df, df_user = load_data(dataPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "P_rdCx53amka",
        "outputId": "95d775fe-1236-4319-a11e-7f2bce88b664"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       UID   MID  rate       time\n",
              "0        1     1     5  874965758\n",
              "1        1     2     3  876893171\n",
              "2        1     3     4  878542960\n",
              "3        1     4     3  876893119\n",
              "4        1     5     3  889751712\n",
              "...    ...   ...   ...        ...\n",
              "79995  943  1067     2  875501756\n",
              "79996  943  1074     4  888640250\n",
              "79997  943  1188     3  888640250\n",
              "79998  943  1228     3  888640275\n",
              "79999  943  1330     3  888692465\n",
              "\n",
              "[80000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4abeebf-00fd-4e2b-b3e8-8910b65d933b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UID</th>\n",
              "      <th>MID</th>\n",
              "      <th>rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>874965758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>876893171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>878542960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>876893119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>889751712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79995</th>\n",
              "      <td>943</td>\n",
              "      <td>1067</td>\n",
              "      <td>2</td>\n",
              "      <td>875501756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79996</th>\n",
              "      <td>943</td>\n",
              "      <td>1074</td>\n",
              "      <td>4</td>\n",
              "      <td>888640250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79997</th>\n",
              "      <td>943</td>\n",
              "      <td>1188</td>\n",
              "      <td>3</td>\n",
              "      <td>888640250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79998</th>\n",
              "      <td>943</td>\n",
              "      <td>1228</td>\n",
              "      <td>3</td>\n",
              "      <td>888640275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79999</th>\n",
              "      <td>943</td>\n",
              "      <td>1330</td>\n",
              "      <td>3</td>\n",
              "      <td>888692465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4abeebf-00fd-4e2b-b3e8-8910b65d933b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4abeebf-00fd-4e2b-b3e8-8910b65d933b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4abeebf-00fd-4e2b-b3e8-8910b65d933b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "-lKMxb_ranwe",
        "outputId": "99016550-78c4-469e-8b59-a629d1d5dedb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     UID  age1  age2  age3  age4  age5  age6  gender1  gender2  job1  ...  \\\n",
              "0      1   0.0   0.0   1.0   0.0   0.0   0.0      0.0      1.0   0.0  ...   \n",
              "1      2   0.0   0.0   0.0   0.0   0.0   1.0      1.0      0.0   0.0  ...   \n",
              "2      3   0.0   0.0   1.0   0.0   0.0   0.0      0.0      1.0   0.0  ...   \n",
              "3      4   0.0   0.0   1.0   0.0   0.0   0.0      0.0      1.0   0.0  ...   \n",
              "4      5   0.0   0.0   0.0   1.0   0.0   0.0      1.0      0.0   0.0  ...   \n",
              "..   ...   ...   ...   ...   ...   ...   ...      ...      ...   ...  ...   \n",
              "938  939   0.0   0.0   1.0   0.0   0.0   0.0      1.0      0.0   0.0  ...   \n",
              "939  940   0.0   0.0   0.0   1.0   0.0   0.0      0.0      1.0   1.0  ...   \n",
              "940  941   0.0   1.0   0.0   0.0   0.0   0.0      0.0      1.0   0.0  ...   \n",
              "941  942   0.0   0.0   0.0   0.0   1.0   0.0      1.0      0.0   0.0  ...   \n",
              "942  943   0.0   0.0   1.0   0.0   0.0   0.0      0.0      1.0   0.0  ...   \n",
              "\n",
              "     job12  job13  job14  job15  job16  job17  job18  job19  job20  job21  \n",
              "0      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
              "1      0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
              "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
              "4      0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
              "938    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
              "939    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "940    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
              "941    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "942    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
              "\n",
              "[943 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-934160c8-f1fc-43f7-a067-aaa9c799a169\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UID</th>\n",
              "      <th>age1</th>\n",
              "      <th>age2</th>\n",
              "      <th>age3</th>\n",
              "      <th>age4</th>\n",
              "      <th>age5</th>\n",
              "      <th>age6</th>\n",
              "      <th>gender1</th>\n",
              "      <th>gender2</th>\n",
              "      <th>job1</th>\n",
              "      <th>...</th>\n",
              "      <th>job12</th>\n",
              "      <th>job13</th>\n",
              "      <th>job14</th>\n",
              "      <th>job15</th>\n",
              "      <th>job16</th>\n",
              "      <th>job17</th>\n",
              "      <th>job18</th>\n",
              "      <th>job19</th>\n",
              "      <th>job20</th>\n",
              "      <th>job21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-934160c8-f1fc-43f7-a067-aaa9c799a169')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-934160c8-f1fc-43f7-a067-aaa9c799a169 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-934160c8-f1fc-43f7-a067-aaa9c799a169');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df_user\n",
        "#has been processed by OnehotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm5kzNLMaego"
      },
      "source": [
        "## 5. Buid Graph and Extracfeature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWA7h9Poac8M",
        "outputId": "a22cef2c-1e94-4ea0-917b-9da2bcf27f9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "train_model(df, df_user)\n",
        "dataPath = 'data100k/'\n",
        "X_train = pd.read_pickle(dataPath + 'x_train_alpha(0.01).pkl').values.astype(float)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2j0Gvf5auBC"
      },
      "source": [
        "## 6. Train Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2JDT0yCQatWP"
      },
      "outputs": [],
      "source": [
        "# Define autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoded_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(input_dim, 16), nn.ReLU(),\n",
        "                                     nn.Linear(16, encoded_dim))\n",
        "        self.decoder = nn.Sequential(nn.Linear(encoded_dim, 16), nn.ReLU(),\n",
        "                                     nn.Linear(16, input_dim), nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_l1_loss(self, w):\n",
        "      return torch.abs(w).sum()\n",
        "\n",
        "    def compute_l2_loss(self, w):\n",
        "      return torch.square(w).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-MfAnZ-bREz",
        "outputId": "edf625da-8f19-47a1-8105-f749a929cbcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0708\n",
            "Epoch [10/100], Loss: 0.0769\n",
            "Epoch [10/100], Loss: 0.0743\n",
            "Epoch [10/100], Loss: 0.0736\n",
            "Epoch [10/100], Loss: 0.0697\n",
            "Epoch [10/100], Loss: 0.0695\n",
            "Epoch [10/100], Loss: 0.0700\n",
            "Epoch [10/100], Loss: 0.0709\n",
            "Epoch [10/100], Loss: 0.0733\n",
            "Epoch [10/100], Loss: 0.0756\n",
            "Epoch [10/100], Loss: 0.0640\n",
            "Epoch [10/100], Loss: 0.0695\n",
            "Epoch [10/100], Loss: 0.0785\n",
            "Epoch [10/100], Loss: 0.0691\n",
            "Epoch [10/100], Loss: 0.0791\n",
            "Epoch [10/100], Loss: 0.0704\n",
            "Epoch [10/100], Loss: 0.0741\n",
            "Epoch [10/100], Loss: 0.0749\n",
            "Epoch [10/100], Loss: 0.0699\n",
            "Epoch [10/100], Loss: 0.0662\n",
            "Epoch [10/100], Loss: 0.0776\n",
            "Epoch [10/100], Loss: 0.0696\n",
            "Epoch [10/100], Loss: 0.0753\n",
            "Epoch [10/100], Loss: 0.0744\n",
            "Epoch [10/100], Loss: 0.0609\n",
            "Epoch [10/100], Loss: 0.0736\n",
            "Epoch [10/100], Loss: 0.0792\n",
            "Epoch [10/100], Loss: 0.0792\n",
            "Epoch [10/100], Loss: 0.0639\n",
            "Epoch [10/100], Loss: 0.0785\n",
            "Epoch [10/100], Loss: 0.0685\n",
            "Epoch [10/100], Loss: 0.0739\n",
            "Epoch [10/100], Loss: 0.0722\n",
            "Epoch [10/100], Loss: 0.0705\n",
            "Epoch [10/100], Loss: 0.0775\n",
            "Epoch [10/100], Loss: 0.0683\n",
            "Epoch [10/100], Loss: 0.0690\n",
            "Epoch [10/100], Loss: 0.0726\n",
            "Epoch [10/100], Loss: 0.0757\n",
            "Epoch [10/100], Loss: 0.0718\n",
            "Epoch [10/100], Loss: 0.0772\n",
            "Epoch [10/100], Loss: 0.0770\n",
            "Epoch [10/100], Loss: 0.0744\n",
            "Epoch [10/100], Loss: 0.0790\n",
            "Epoch [10/100], Loss: 0.0776\n",
            "Epoch [10/100], Loss: 0.0793\n",
            "Epoch [10/100], Loss: 0.0709\n",
            "Epoch [10/100], Loss: 0.0716\n",
            "Epoch [10/100], Loss: 0.0743\n",
            "Epoch [10/100], Loss: 0.0748\n",
            "Epoch [10/100], Loss: 0.0754\n",
            "Epoch [10/100], Loss: 0.0692\n",
            "Epoch [10/100], Loss: 0.0734\n",
            "Epoch [10/100], Loss: 0.0809\n",
            "Epoch [10/100], Loss: 0.0748\n",
            "Epoch [10/100], Loss: 0.0774\n",
            "Epoch [10/100], Loss: 0.0709\n",
            "Epoch [10/100], Loss: 0.0718\n",
            "Epoch [10/100], Loss: 0.0659\n",
            "Epoch [10/100], Loss: 0.0851\n",
            "Epoch [10/100], Loss: 0.0769\n",
            "Epoch [10/100], Loss: 0.0777\n",
            "Epoch [10/100], Loss: 0.0734\n",
            "Epoch [10/100], Loss: 0.0703\n",
            "Epoch [10/100], Loss: 0.0745\n",
            "Epoch [10/100], Loss: 0.0772\n",
            "Epoch [10/100], Loss: 0.0691\n",
            "Epoch [10/100], Loss: 0.0748\n",
            "Epoch [10/100], Loss: 0.0792\n",
            "Epoch [10/100], Loss: 0.0710\n",
            "Epoch [10/100], Loss: 0.0753\n",
            "Epoch [10/100], Loss: 0.0818\n",
            "Epoch [10/100], Loss: 0.0759\n",
            "Epoch [10/100], Loss: 0.0820\n",
            "Epoch [10/100], Loss: 0.0687\n",
            "Epoch [10/100], Loss: 0.0820\n",
            "Epoch [10/100], Loss: 0.0660\n",
            "Epoch [10/100], Loss: 0.0641\n",
            "Epoch [10/100], Loss: 0.0730\n",
            "Epoch [10/100], Loss: 0.0754\n",
            "Epoch [10/100], Loss: 0.0817\n",
            "Epoch [10/100], Loss: 0.0684\n",
            "Epoch [10/100], Loss: 0.0703\n",
            "Epoch [10/100], Loss: 0.0723\n",
            "Epoch [10/100], Loss: 0.0721\n",
            "Epoch [10/100], Loss: 0.0816\n",
            "Epoch [10/100], Loss: 0.0673\n",
            "Epoch [10/100], Loss: 0.0805\n",
            "Epoch [10/100], Loss: 0.0770\n",
            "Epoch [10/100], Loss: 0.0737\n",
            "Epoch [10/100], Loss: 0.0762\n",
            "Epoch [10/100], Loss: 0.0749\n",
            "Epoch [10/100], Loss: 0.0725\n",
            "Epoch [10/100], Loss: 0.0704\n",
            "Epoch [10/100], Loss: 0.0718\n",
            "Epoch [20/100], Loss: 0.0709\n",
            "Epoch [20/100], Loss: 0.0769\n",
            "Epoch [20/100], Loss: 0.0742\n",
            "Epoch [20/100], Loss: 0.0736\n",
            "Epoch [20/100], Loss: 0.0698\n",
            "Epoch [20/100], Loss: 0.0696\n",
            "Epoch [20/100], Loss: 0.0701\n",
            "Epoch [20/100], Loss: 0.0709\n",
            "Epoch [20/100], Loss: 0.0733\n",
            "Epoch [20/100], Loss: 0.0757\n",
            "Epoch [20/100], Loss: 0.0641\n",
            "Epoch [20/100], Loss: 0.0695\n",
            "Epoch [20/100], Loss: 0.0785\n",
            "Epoch [20/100], Loss: 0.0692\n",
            "Epoch [20/100], Loss: 0.0791\n",
            "Epoch [20/100], Loss: 0.0704\n",
            "Epoch [20/100], Loss: 0.0742\n",
            "Epoch [20/100], Loss: 0.0749\n",
            "Epoch [20/100], Loss: 0.0699\n",
            "Epoch [20/100], Loss: 0.0662\n",
            "Epoch [20/100], Loss: 0.0777\n",
            "Epoch [20/100], Loss: 0.0696\n",
            "Epoch [20/100], Loss: 0.0753\n",
            "Epoch [20/100], Loss: 0.0743\n",
            "Epoch [20/100], Loss: 0.0609\n",
            "Epoch [20/100], Loss: 0.0736\n",
            "Epoch [20/100], Loss: 0.0792\n",
            "Epoch [20/100], Loss: 0.0792\n",
            "Epoch [20/100], Loss: 0.0639\n",
            "Epoch [20/100], Loss: 0.0785\n",
            "Epoch [20/100], Loss: 0.0685\n",
            "Epoch [20/100], Loss: 0.0739\n",
            "Epoch [20/100], Loss: 0.0723\n",
            "Epoch [20/100], Loss: 0.0706\n",
            "Epoch [20/100], Loss: 0.0775\n",
            "Epoch [20/100], Loss: 0.0684\n",
            "Epoch [20/100], Loss: 0.0690\n",
            "Epoch [20/100], Loss: 0.0726\n",
            "Epoch [20/100], Loss: 0.0756\n",
            "Epoch [20/100], Loss: 0.0717\n",
            "Epoch [20/100], Loss: 0.0772\n",
            "Epoch [20/100], Loss: 0.0769\n",
            "Epoch [20/100], Loss: 0.0744\n",
            "Epoch [20/100], Loss: 0.0790\n",
            "Epoch [20/100], Loss: 0.0775\n",
            "Epoch [20/100], Loss: 0.0793\n",
            "Epoch [20/100], Loss: 0.0709\n",
            "Epoch [20/100], Loss: 0.0716\n",
            "Epoch [20/100], Loss: 0.0744\n",
            "Epoch [20/100], Loss: 0.0749\n",
            "Epoch [20/100], Loss: 0.0754\n",
            "Epoch [20/100], Loss: 0.0692\n",
            "Epoch [20/100], Loss: 0.0734\n",
            "Epoch [20/100], Loss: 0.0810\n",
            "Epoch [20/100], Loss: 0.0749\n",
            "Epoch [20/100], Loss: 0.0774\n",
            "Epoch [20/100], Loss: 0.0708\n",
            "Epoch [20/100], Loss: 0.0718\n",
            "Epoch [20/100], Loss: 0.0659\n",
            "Epoch [20/100], Loss: 0.0851\n",
            "Epoch [20/100], Loss: 0.0769\n",
            "Epoch [20/100], Loss: 0.0778\n",
            "Epoch [20/100], Loss: 0.0734\n",
            "Epoch [20/100], Loss: 0.0703\n",
            "Epoch [20/100], Loss: 0.0745\n",
            "Epoch [20/100], Loss: 0.0772\n",
            "Epoch [20/100], Loss: 0.0691\n",
            "Epoch [20/100], Loss: 0.0748\n",
            "Epoch [20/100], Loss: 0.0793\n",
            "Epoch [20/100], Loss: 0.0711\n",
            "Epoch [20/100], Loss: 0.0753\n",
            "Epoch [20/100], Loss: 0.0818\n",
            "Epoch [20/100], Loss: 0.0759\n",
            "Epoch [20/100], Loss: 0.0821\n",
            "Epoch [20/100], Loss: 0.0687\n",
            "Epoch [20/100], Loss: 0.0820\n",
            "Epoch [20/100], Loss: 0.0660\n",
            "Epoch [20/100], Loss: 0.0641\n",
            "Epoch [20/100], Loss: 0.0730\n",
            "Epoch [20/100], Loss: 0.0754\n",
            "Epoch [20/100], Loss: 0.0817\n",
            "Epoch [20/100], Loss: 0.0685\n",
            "Epoch [20/100], Loss: 0.0703\n",
            "Epoch [20/100], Loss: 0.0724\n",
            "Epoch [20/100], Loss: 0.0721\n",
            "Epoch [20/100], Loss: 0.0816\n",
            "Epoch [20/100], Loss: 0.0673\n",
            "Epoch [20/100], Loss: 0.0805\n",
            "Epoch [20/100], Loss: 0.0770\n",
            "Epoch [20/100], Loss: 0.0737\n",
            "Epoch [20/100], Loss: 0.0763\n",
            "Epoch [20/100], Loss: 0.0749\n",
            "Epoch [20/100], Loss: 0.0726\n",
            "Epoch [20/100], Loss: 0.0705\n",
            "Epoch [20/100], Loss: 0.0719\n",
            "Epoch [30/100], Loss: 0.0709\n",
            "Epoch [30/100], Loss: 0.0769\n",
            "Epoch [30/100], Loss: 0.0742\n",
            "Epoch [30/100], Loss: 0.0736\n",
            "Epoch [30/100], Loss: 0.0698\n",
            "Epoch [30/100], Loss: 0.0696\n",
            "Epoch [30/100], Loss: 0.0701\n",
            "Epoch [30/100], Loss: 0.0710\n",
            "Epoch [30/100], Loss: 0.0733\n",
            "Epoch [30/100], Loss: 0.0757\n",
            "Epoch [30/100], Loss: 0.0641\n",
            "Epoch [30/100], Loss: 0.0695\n",
            "Epoch [30/100], Loss: 0.0785\n",
            "Epoch [30/100], Loss: 0.0692\n",
            "Epoch [30/100], Loss: 0.0791\n",
            "Epoch [30/100], Loss: 0.0704\n",
            "Epoch [30/100], Loss: 0.0742\n",
            "Epoch [30/100], Loss: 0.0749\n",
            "Epoch [30/100], Loss: 0.0699\n",
            "Epoch [30/100], Loss: 0.0662\n",
            "Epoch [30/100], Loss: 0.0777\n",
            "Epoch [30/100], Loss: 0.0697\n",
            "Epoch [30/100], Loss: 0.0753\n",
            "Epoch [30/100], Loss: 0.0744\n",
            "Epoch [30/100], Loss: 0.0609\n",
            "Epoch [30/100], Loss: 0.0735\n",
            "Epoch [30/100], Loss: 0.0792\n",
            "Epoch [30/100], Loss: 0.0792\n",
            "Epoch [30/100], Loss: 0.0640\n",
            "Epoch [30/100], Loss: 0.0785\n",
            "Epoch [30/100], Loss: 0.0685\n",
            "Epoch [30/100], Loss: 0.0738\n",
            "Epoch [30/100], Loss: 0.0722\n",
            "Epoch [30/100], Loss: 0.0706\n",
            "Epoch [30/100], Loss: 0.0775\n",
            "Epoch [30/100], Loss: 0.0684\n",
            "Epoch [30/100], Loss: 0.0690\n",
            "Epoch [30/100], Loss: 0.0726\n",
            "Epoch [30/100], Loss: 0.0756\n",
            "Epoch [30/100], Loss: 0.0717\n",
            "Epoch [30/100], Loss: 0.0772\n",
            "Epoch [30/100], Loss: 0.0770\n",
            "Epoch [30/100], Loss: 0.0744\n",
            "Epoch [30/100], Loss: 0.0790\n",
            "Epoch [30/100], Loss: 0.0776\n",
            "Epoch [30/100], Loss: 0.0793\n",
            "Epoch [30/100], Loss: 0.0709\n",
            "Epoch [30/100], Loss: 0.0716\n",
            "Epoch [30/100], Loss: 0.0744\n",
            "Epoch [30/100], Loss: 0.0749\n",
            "Epoch [30/100], Loss: 0.0754\n",
            "Epoch [30/100], Loss: 0.0692\n",
            "Epoch [30/100], Loss: 0.0735\n",
            "Epoch [30/100], Loss: 0.0810\n",
            "Epoch [30/100], Loss: 0.0749\n",
            "Epoch [30/100], Loss: 0.0774\n",
            "Epoch [30/100], Loss: 0.0709\n",
            "Epoch [30/100], Loss: 0.0718\n",
            "Epoch [30/100], Loss: 0.0659\n",
            "Epoch [30/100], Loss: 0.0851\n",
            "Epoch [30/100], Loss: 0.0769\n",
            "Epoch [30/100], Loss: 0.0778\n",
            "Epoch [30/100], Loss: 0.0734\n",
            "Epoch [30/100], Loss: 0.0703\n",
            "Epoch [30/100], Loss: 0.0745\n",
            "Epoch [30/100], Loss: 0.0772\n",
            "Epoch [30/100], Loss: 0.0691\n",
            "Epoch [30/100], Loss: 0.0748\n",
            "Epoch [30/100], Loss: 0.0793\n",
            "Epoch [30/100], Loss: 0.0711\n",
            "Epoch [30/100], Loss: 0.0753\n",
            "Epoch [30/100], Loss: 0.0818\n",
            "Epoch [30/100], Loss: 0.0759\n",
            "Epoch [30/100], Loss: 0.0820\n",
            "Epoch [30/100], Loss: 0.0687\n",
            "Epoch [30/100], Loss: 0.0820\n",
            "Epoch [30/100], Loss: 0.0660\n",
            "Epoch [30/100], Loss: 0.0641\n",
            "Epoch [30/100], Loss: 0.0730\n",
            "Epoch [30/100], Loss: 0.0754\n",
            "Epoch [30/100], Loss: 0.0816\n",
            "Epoch [30/100], Loss: 0.0685\n",
            "Epoch [30/100], Loss: 0.0703\n",
            "Epoch [30/100], Loss: 0.0723\n",
            "Epoch [30/100], Loss: 0.0721\n",
            "Epoch [30/100], Loss: 0.0815\n",
            "Epoch [30/100], Loss: 0.0673\n",
            "Epoch [30/100], Loss: 0.0805\n",
            "Epoch [30/100], Loss: 0.0770\n",
            "Epoch [30/100], Loss: 0.0737\n",
            "Epoch [30/100], Loss: 0.0763\n",
            "Epoch [30/100], Loss: 0.0749\n",
            "Epoch [30/100], Loss: 0.0726\n",
            "Epoch [30/100], Loss: 0.0705\n",
            "Epoch [30/100], Loss: 0.0719\n",
            "Epoch [40/100], Loss: 0.0708\n",
            "Epoch [40/100], Loss: 0.0768\n",
            "Epoch [40/100], Loss: 0.0742\n",
            "Epoch [40/100], Loss: 0.0736\n",
            "Epoch [40/100], Loss: 0.0698\n",
            "Epoch [40/100], Loss: 0.0696\n",
            "Epoch [40/100], Loss: 0.0701\n",
            "Epoch [40/100], Loss: 0.0710\n",
            "Epoch [40/100], Loss: 0.0733\n",
            "Epoch [40/100], Loss: 0.0757\n",
            "Epoch [40/100], Loss: 0.0641\n",
            "Epoch [40/100], Loss: 0.0695\n",
            "Epoch [40/100], Loss: 0.0785\n",
            "Epoch [40/100], Loss: 0.0692\n",
            "Epoch [40/100], Loss: 0.0792\n",
            "Epoch [40/100], Loss: 0.0705\n",
            "Epoch [40/100], Loss: 0.0742\n",
            "Epoch [40/100], Loss: 0.0750\n",
            "Epoch [40/100], Loss: 0.0699\n",
            "Epoch [40/100], Loss: 0.0662\n",
            "Epoch [40/100], Loss: 0.0776\n",
            "Epoch [40/100], Loss: 0.0697\n",
            "Epoch [40/100], Loss: 0.0753\n",
            "Epoch [40/100], Loss: 0.0744\n",
            "Epoch [40/100], Loss: 0.0609\n",
            "Epoch [40/100], Loss: 0.0736\n",
            "Epoch [40/100], Loss: 0.0792\n",
            "Epoch [40/100], Loss: 0.0791\n",
            "Epoch [40/100], Loss: 0.0639\n",
            "Epoch [40/100], Loss: 0.0786\n",
            "Epoch [40/100], Loss: 0.0685\n",
            "Epoch [40/100], Loss: 0.0738\n",
            "Epoch [40/100], Loss: 0.0722\n",
            "Epoch [40/100], Loss: 0.0706\n",
            "Epoch [40/100], Loss: 0.0775\n",
            "Epoch [40/100], Loss: 0.0683\n",
            "Epoch [40/100], Loss: 0.0690\n",
            "Epoch [40/100], Loss: 0.0726\n",
            "Epoch [40/100], Loss: 0.0757\n",
            "Epoch [40/100], Loss: 0.0718\n",
            "Epoch [40/100], Loss: 0.0772\n",
            "Epoch [40/100], Loss: 0.0770\n",
            "Epoch [40/100], Loss: 0.0744\n",
            "Epoch [40/100], Loss: 0.0790\n",
            "Epoch [40/100], Loss: 0.0776\n",
            "Epoch [40/100], Loss: 0.0793\n",
            "Epoch [40/100], Loss: 0.0709\n",
            "Epoch [40/100], Loss: 0.0715\n",
            "Epoch [40/100], Loss: 0.0743\n",
            "Epoch [40/100], Loss: 0.0749\n",
            "Epoch [40/100], Loss: 0.0754\n",
            "Epoch [40/100], Loss: 0.0692\n",
            "Epoch [40/100], Loss: 0.0734\n",
            "Epoch [40/100], Loss: 0.0810\n",
            "Epoch [40/100], Loss: 0.0748\n",
            "Epoch [40/100], Loss: 0.0774\n",
            "Epoch [40/100], Loss: 0.0708\n",
            "Epoch [40/100], Loss: 0.0718\n",
            "Epoch [40/100], Loss: 0.0659\n",
            "Epoch [40/100], Loss: 0.0851\n",
            "Epoch [40/100], Loss: 0.0769\n",
            "Epoch [40/100], Loss: 0.0778\n",
            "Epoch [40/100], Loss: 0.0735\n",
            "Epoch [40/100], Loss: 0.0703\n",
            "Epoch [40/100], Loss: 0.0744\n",
            "Epoch [40/100], Loss: 0.0772\n",
            "Epoch [40/100], Loss: 0.0691\n",
            "Epoch [40/100], Loss: 0.0748\n",
            "Epoch [40/100], Loss: 0.0793\n",
            "Epoch [40/100], Loss: 0.0711\n",
            "Epoch [40/100], Loss: 0.0754\n",
            "Epoch [40/100], Loss: 0.0818\n",
            "Epoch [40/100], Loss: 0.0760\n",
            "Epoch [40/100], Loss: 0.0820\n",
            "Epoch [40/100], Loss: 0.0688\n",
            "Epoch [40/100], Loss: 0.0820\n",
            "Epoch [40/100], Loss: 0.0660\n",
            "Epoch [40/100], Loss: 0.0641\n",
            "Epoch [40/100], Loss: 0.0730\n",
            "Epoch [40/100], Loss: 0.0755\n",
            "Epoch [40/100], Loss: 0.0816\n",
            "Epoch [40/100], Loss: 0.0684\n",
            "Epoch [40/100], Loss: 0.0703\n",
            "Epoch [40/100], Loss: 0.0723\n",
            "Epoch [40/100], Loss: 0.0721\n",
            "Epoch [40/100], Loss: 0.0816\n",
            "Epoch [40/100], Loss: 0.0673\n",
            "Epoch [40/100], Loss: 0.0805\n",
            "Epoch [40/100], Loss: 0.0770\n",
            "Epoch [40/100], Loss: 0.0737\n",
            "Epoch [40/100], Loss: 0.0763\n",
            "Epoch [40/100], Loss: 0.0749\n",
            "Epoch [40/100], Loss: 0.0726\n",
            "Epoch [40/100], Loss: 0.0705\n",
            "Epoch [40/100], Loss: 0.0719\n",
            "Epoch [50/100], Loss: 0.0709\n",
            "Epoch [50/100], Loss: 0.0769\n",
            "Epoch [50/100], Loss: 0.0742\n",
            "Epoch [50/100], Loss: 0.0736\n",
            "Epoch [50/100], Loss: 0.0698\n",
            "Epoch [50/100], Loss: 0.0696\n",
            "Epoch [50/100], Loss: 0.0701\n",
            "Epoch [50/100], Loss: 0.0710\n",
            "Epoch [50/100], Loss: 0.0733\n",
            "Epoch [50/100], Loss: 0.0757\n",
            "Epoch [50/100], Loss: 0.0641\n",
            "Epoch [50/100], Loss: 0.0695\n",
            "Epoch [50/100], Loss: 0.0785\n",
            "Epoch [50/100], Loss: 0.0692\n",
            "Epoch [50/100], Loss: 0.0791\n",
            "Epoch [50/100], Loss: 0.0704\n",
            "Epoch [50/100], Loss: 0.0742\n",
            "Epoch [50/100], Loss: 0.0750\n",
            "Epoch [50/100], Loss: 0.0699\n",
            "Epoch [50/100], Loss: 0.0663\n",
            "Epoch [50/100], Loss: 0.0776\n",
            "Epoch [50/100], Loss: 0.0696\n",
            "Epoch [50/100], Loss: 0.0753\n",
            "Epoch [50/100], Loss: 0.0744\n",
            "Epoch [50/100], Loss: 0.0609\n",
            "Epoch [50/100], Loss: 0.0736\n",
            "Epoch [50/100], Loss: 0.0792\n",
            "Epoch [50/100], Loss: 0.0792\n",
            "Epoch [50/100], Loss: 0.0640\n",
            "Epoch [50/100], Loss: 0.0785\n",
            "Epoch [50/100], Loss: 0.0685\n",
            "Epoch [50/100], Loss: 0.0739\n",
            "Epoch [50/100], Loss: 0.0722\n",
            "Epoch [50/100], Loss: 0.0706\n",
            "Epoch [50/100], Loss: 0.0775\n",
            "Epoch [50/100], Loss: 0.0684\n",
            "Epoch [50/100], Loss: 0.0690\n",
            "Epoch [50/100], Loss: 0.0726\n",
            "Epoch [50/100], Loss: 0.0756\n",
            "Epoch [50/100], Loss: 0.0717\n",
            "Epoch [50/100], Loss: 0.0772\n",
            "Epoch [50/100], Loss: 0.0770\n",
            "Epoch [50/100], Loss: 0.0744\n",
            "Epoch [50/100], Loss: 0.0790\n",
            "Epoch [50/100], Loss: 0.0776\n",
            "Epoch [50/100], Loss: 0.0792\n",
            "Epoch [50/100], Loss: 0.0709\n",
            "Epoch [50/100], Loss: 0.0716\n",
            "Epoch [50/100], Loss: 0.0744\n",
            "Epoch [50/100], Loss: 0.0749\n",
            "Epoch [50/100], Loss: 0.0754\n",
            "Epoch [50/100], Loss: 0.0692\n",
            "Epoch [50/100], Loss: 0.0735\n",
            "Epoch [50/100], Loss: 0.0810\n",
            "Epoch [50/100], Loss: 0.0749\n",
            "Epoch [50/100], Loss: 0.0775\n",
            "Epoch [50/100], Loss: 0.0709\n",
            "Epoch [50/100], Loss: 0.0718\n",
            "Epoch [50/100], Loss: 0.0658\n",
            "Epoch [50/100], Loss: 0.0851\n",
            "Epoch [50/100], Loss: 0.0770\n",
            "Epoch [50/100], Loss: 0.0778\n",
            "Epoch [50/100], Loss: 0.0734\n",
            "Epoch [50/100], Loss: 0.0703\n",
            "Epoch [50/100], Loss: 0.0745\n",
            "Epoch [50/100], Loss: 0.0772\n",
            "Epoch [50/100], Loss: 0.0691\n",
            "Epoch [50/100], Loss: 0.0748\n",
            "Epoch [50/100], Loss: 0.0793\n",
            "Epoch [50/100], Loss: 0.0710\n",
            "Epoch [50/100], Loss: 0.0753\n",
            "Epoch [50/100], Loss: 0.0818\n",
            "Epoch [50/100], Loss: 0.0760\n",
            "Epoch [50/100], Loss: 0.0821\n",
            "Epoch [50/100], Loss: 0.0687\n",
            "Epoch [50/100], Loss: 0.0820\n",
            "Epoch [50/100], Loss: 0.0660\n",
            "Epoch [50/100], Loss: 0.0641\n",
            "Epoch [50/100], Loss: 0.0730\n",
            "Epoch [50/100], Loss: 0.0755\n",
            "Epoch [50/100], Loss: 0.0817\n",
            "Epoch [50/100], Loss: 0.0684\n",
            "Epoch [50/100], Loss: 0.0703\n",
            "Epoch [50/100], Loss: 0.0723\n",
            "Epoch [50/100], Loss: 0.0721\n",
            "Epoch [50/100], Loss: 0.0815\n",
            "Epoch [50/100], Loss: 0.0673\n",
            "Epoch [50/100], Loss: 0.0805\n",
            "Epoch [50/100], Loss: 0.0770\n",
            "Epoch [50/100], Loss: 0.0737\n",
            "Epoch [50/100], Loss: 0.0762\n",
            "Epoch [50/100], Loss: 0.0749\n",
            "Epoch [50/100], Loss: 0.0726\n",
            "Epoch [50/100], Loss: 0.0704\n",
            "Epoch [50/100], Loss: 0.0719\n",
            "Epoch [60/100], Loss: 0.0709\n",
            "Epoch [60/100], Loss: 0.0769\n",
            "Epoch [60/100], Loss: 0.0742\n",
            "Epoch [60/100], Loss: 0.0736\n",
            "Epoch [60/100], Loss: 0.0698\n",
            "Epoch [60/100], Loss: 0.0696\n",
            "Epoch [60/100], Loss: 0.0701\n",
            "Epoch [60/100], Loss: 0.0709\n",
            "Epoch [60/100], Loss: 0.0733\n",
            "Epoch [60/100], Loss: 0.0757\n",
            "Epoch [60/100], Loss: 0.0641\n",
            "Epoch [60/100], Loss: 0.0695\n",
            "Epoch [60/100], Loss: 0.0785\n",
            "Epoch [60/100], Loss: 0.0692\n",
            "Epoch [60/100], Loss: 0.0792\n",
            "Epoch [60/100], Loss: 0.0704\n",
            "Epoch [60/100], Loss: 0.0742\n",
            "Epoch [60/100], Loss: 0.0750\n",
            "Epoch [60/100], Loss: 0.0699\n",
            "Epoch [60/100], Loss: 0.0662\n",
            "Epoch [60/100], Loss: 0.0776\n",
            "Epoch [60/100], Loss: 0.0696\n",
            "Epoch [60/100], Loss: 0.0753\n",
            "Epoch [60/100], Loss: 0.0744\n",
            "Epoch [60/100], Loss: 0.0609\n",
            "Epoch [60/100], Loss: 0.0736\n",
            "Epoch [60/100], Loss: 0.0792\n",
            "Epoch [60/100], Loss: 0.0792\n",
            "Epoch [60/100], Loss: 0.0640\n",
            "Epoch [60/100], Loss: 0.0785\n",
            "Epoch [60/100], Loss: 0.0685\n",
            "Epoch [60/100], Loss: 0.0738\n",
            "Epoch [60/100], Loss: 0.0722\n",
            "Epoch [60/100], Loss: 0.0706\n",
            "Epoch [60/100], Loss: 0.0776\n",
            "Epoch [60/100], Loss: 0.0683\n",
            "Epoch [60/100], Loss: 0.0689\n",
            "Epoch [60/100], Loss: 0.0726\n",
            "Epoch [60/100], Loss: 0.0756\n",
            "Epoch [60/100], Loss: 0.0717\n",
            "Epoch [60/100], Loss: 0.0772\n",
            "Epoch [60/100], Loss: 0.0770\n",
            "Epoch [60/100], Loss: 0.0744\n",
            "Epoch [60/100], Loss: 0.0790\n",
            "Epoch [60/100], Loss: 0.0775\n",
            "Epoch [60/100], Loss: 0.0792\n",
            "Epoch [60/100], Loss: 0.0709\n",
            "Epoch [60/100], Loss: 0.0716\n",
            "Epoch [60/100], Loss: 0.0744\n",
            "Epoch [60/100], Loss: 0.0749\n",
            "Epoch [60/100], Loss: 0.0754\n",
            "Epoch [60/100], Loss: 0.0692\n",
            "Epoch [60/100], Loss: 0.0735\n",
            "Epoch [60/100], Loss: 0.0811\n",
            "Epoch [60/100], Loss: 0.0749\n",
            "Epoch [60/100], Loss: 0.0774\n",
            "Epoch [60/100], Loss: 0.0708\n",
            "Epoch [60/100], Loss: 0.0718\n",
            "Epoch [60/100], Loss: 0.0659\n",
            "Epoch [60/100], Loss: 0.0851\n",
            "Epoch [60/100], Loss: 0.0770\n",
            "Epoch [60/100], Loss: 0.0778\n",
            "Epoch [60/100], Loss: 0.0734\n",
            "Epoch [60/100], Loss: 0.0703\n",
            "Epoch [60/100], Loss: 0.0745\n",
            "Epoch [60/100], Loss: 0.0772\n",
            "Epoch [60/100], Loss: 0.0691\n",
            "Epoch [60/100], Loss: 0.0748\n",
            "Epoch [60/100], Loss: 0.0792\n",
            "Epoch [60/100], Loss: 0.0711\n",
            "Epoch [60/100], Loss: 0.0753\n",
            "Epoch [60/100], Loss: 0.0818\n",
            "Epoch [60/100], Loss: 0.0760\n",
            "Epoch [60/100], Loss: 0.0821\n",
            "Epoch [60/100], Loss: 0.0687\n",
            "Epoch [60/100], Loss: 0.0820\n",
            "Epoch [60/100], Loss: 0.0660\n",
            "Epoch [60/100], Loss: 0.0642\n",
            "Epoch [60/100], Loss: 0.0730\n",
            "Epoch [60/100], Loss: 0.0754\n",
            "Epoch [60/100], Loss: 0.0816\n",
            "Epoch [60/100], Loss: 0.0685\n",
            "Epoch [60/100], Loss: 0.0704\n",
            "Epoch [60/100], Loss: 0.0724\n",
            "Epoch [60/100], Loss: 0.0722\n",
            "Epoch [60/100], Loss: 0.0816\n",
            "Epoch [60/100], Loss: 0.0673\n",
            "Epoch [60/100], Loss: 0.0805\n",
            "Epoch [60/100], Loss: 0.0771\n",
            "Epoch [60/100], Loss: 0.0737\n",
            "Epoch [60/100], Loss: 0.0763\n",
            "Epoch [60/100], Loss: 0.0749\n",
            "Epoch [60/100], Loss: 0.0725\n",
            "Epoch [60/100], Loss: 0.0705\n",
            "Epoch [60/100], Loss: 0.0719\n",
            "Epoch [70/100], Loss: 0.0709\n",
            "Epoch [70/100], Loss: 0.0769\n",
            "Epoch [70/100], Loss: 0.0742\n",
            "Epoch [70/100], Loss: 0.0736\n",
            "Epoch [70/100], Loss: 0.0698\n",
            "Epoch [70/100], Loss: 0.0696\n",
            "Epoch [70/100], Loss: 0.0701\n",
            "Epoch [70/100], Loss: 0.0710\n",
            "Epoch [70/100], Loss: 0.0734\n",
            "Epoch [70/100], Loss: 0.0757\n",
            "Epoch [70/100], Loss: 0.0641\n",
            "Epoch [70/100], Loss: 0.0695\n",
            "Epoch [70/100], Loss: 0.0785\n",
            "Epoch [70/100], Loss: 0.0692\n",
            "Epoch [70/100], Loss: 0.0792\n",
            "Epoch [70/100], Loss: 0.0705\n",
            "Epoch [70/100], Loss: 0.0742\n",
            "Epoch [70/100], Loss: 0.0749\n",
            "Epoch [70/100], Loss: 0.0699\n",
            "Epoch [70/100], Loss: 0.0663\n",
            "Epoch [70/100], Loss: 0.0777\n",
            "Epoch [70/100], Loss: 0.0697\n",
            "Epoch [70/100], Loss: 0.0754\n",
            "Epoch [70/100], Loss: 0.0744\n",
            "Epoch [70/100], Loss: 0.0609\n",
            "Epoch [70/100], Loss: 0.0736\n",
            "Epoch [70/100], Loss: 0.0793\n",
            "Epoch [70/100], Loss: 0.0792\n",
            "Epoch [70/100], Loss: 0.0640\n",
            "Epoch [70/100], Loss: 0.0786\n",
            "Epoch [70/100], Loss: 0.0685\n",
            "Epoch [70/100], Loss: 0.0739\n",
            "Epoch [70/100], Loss: 0.0722\n",
            "Epoch [70/100], Loss: 0.0705\n",
            "Epoch [70/100], Loss: 0.0776\n",
            "Epoch [70/100], Loss: 0.0683\n",
            "Epoch [70/100], Loss: 0.0690\n",
            "Epoch [70/100], Loss: 0.0726\n",
            "Epoch [70/100], Loss: 0.0756\n",
            "Epoch [70/100], Loss: 0.0717\n",
            "Epoch [70/100], Loss: 0.0772\n",
            "Epoch [70/100], Loss: 0.0770\n",
            "Epoch [70/100], Loss: 0.0744\n",
            "Epoch [70/100], Loss: 0.0790\n",
            "Epoch [70/100], Loss: 0.0776\n",
            "Epoch [70/100], Loss: 0.0793\n",
            "Epoch [70/100], Loss: 0.0709\n",
            "Epoch [70/100], Loss: 0.0716\n",
            "Epoch [70/100], Loss: 0.0743\n",
            "Epoch [70/100], Loss: 0.0749\n",
            "Epoch [70/100], Loss: 0.0754\n",
            "Epoch [70/100], Loss: 0.0693\n",
            "Epoch [70/100], Loss: 0.0734\n",
            "Epoch [70/100], Loss: 0.0810\n",
            "Epoch [70/100], Loss: 0.0749\n",
            "Epoch [70/100], Loss: 0.0775\n",
            "Epoch [70/100], Loss: 0.0709\n",
            "Epoch [70/100], Loss: 0.0718\n",
            "Epoch [70/100], Loss: 0.0659\n",
            "Epoch [70/100], Loss: 0.0851\n",
            "Epoch [70/100], Loss: 0.0769\n",
            "Epoch [70/100], Loss: 0.0778\n",
            "Epoch [70/100], Loss: 0.0735\n",
            "Epoch [70/100], Loss: 0.0703\n",
            "Epoch [70/100], Loss: 0.0745\n",
            "Epoch [70/100], Loss: 0.0772\n",
            "Epoch [70/100], Loss: 0.0691\n",
            "Epoch [70/100], Loss: 0.0748\n",
            "Epoch [70/100], Loss: 0.0793\n",
            "Epoch [70/100], Loss: 0.0711\n",
            "Epoch [70/100], Loss: 0.0753\n",
            "Epoch [70/100], Loss: 0.0818\n",
            "Epoch [70/100], Loss: 0.0759\n",
            "Epoch [70/100], Loss: 0.0820\n",
            "Epoch [70/100], Loss: 0.0688\n",
            "Epoch [70/100], Loss: 0.0820\n",
            "Epoch [70/100], Loss: 0.0661\n",
            "Epoch [70/100], Loss: 0.0642\n",
            "Epoch [70/100], Loss: 0.0730\n",
            "Epoch [70/100], Loss: 0.0755\n",
            "Epoch [70/100], Loss: 0.0817\n",
            "Epoch [70/100], Loss: 0.0685\n",
            "Epoch [70/100], Loss: 0.0703\n",
            "Epoch [70/100], Loss: 0.0724\n",
            "Epoch [70/100], Loss: 0.0722\n",
            "Epoch [70/100], Loss: 0.0816\n",
            "Epoch [70/100], Loss: 0.0673\n",
            "Epoch [70/100], Loss: 0.0805\n",
            "Epoch [70/100], Loss: 0.0770\n",
            "Epoch [70/100], Loss: 0.0737\n",
            "Epoch [70/100], Loss: 0.0763\n",
            "Epoch [70/100], Loss: 0.0749\n",
            "Epoch [70/100], Loss: 0.0726\n",
            "Epoch [70/100], Loss: 0.0705\n",
            "Epoch [70/100], Loss: 0.0719\n",
            "Epoch [80/100], Loss: 0.0709\n",
            "Epoch [80/100], Loss: 0.0769\n",
            "Epoch [80/100], Loss: 0.0742\n",
            "Epoch [80/100], Loss: 0.0736\n",
            "Epoch [80/100], Loss: 0.0698\n",
            "Epoch [80/100], Loss: 0.0696\n",
            "Epoch [80/100], Loss: 0.0701\n",
            "Epoch [80/100], Loss: 0.0709\n",
            "Epoch [80/100], Loss: 0.0733\n",
            "Epoch [80/100], Loss: 0.0757\n",
            "Epoch [80/100], Loss: 0.0641\n",
            "Epoch [80/100], Loss: 0.0695\n",
            "Epoch [80/100], Loss: 0.0785\n",
            "Epoch [80/100], Loss: 0.0692\n",
            "Epoch [80/100], Loss: 0.0791\n",
            "Epoch [80/100], Loss: 0.0704\n",
            "Epoch [80/100], Loss: 0.0742\n",
            "Epoch [80/100], Loss: 0.0750\n",
            "Epoch [80/100], Loss: 0.0699\n",
            "Epoch [80/100], Loss: 0.0662\n",
            "Epoch [80/100], Loss: 0.0776\n",
            "Epoch [80/100], Loss: 0.0696\n",
            "Epoch [80/100], Loss: 0.0753\n",
            "Epoch [80/100], Loss: 0.0744\n",
            "Epoch [80/100], Loss: 0.0609\n",
            "Epoch [80/100], Loss: 0.0736\n",
            "Epoch [80/100], Loss: 0.0792\n",
            "Epoch [80/100], Loss: 0.0792\n",
            "Epoch [80/100], Loss: 0.0639\n",
            "Epoch [80/100], Loss: 0.0785\n",
            "Epoch [80/100], Loss: 0.0685\n",
            "Epoch [80/100], Loss: 0.0739\n",
            "Epoch [80/100], Loss: 0.0722\n",
            "Epoch [80/100], Loss: 0.0706\n",
            "Epoch [80/100], Loss: 0.0775\n",
            "Epoch [80/100], Loss: 0.0683\n",
            "Epoch [80/100], Loss: 0.0690\n",
            "Epoch [80/100], Loss: 0.0726\n",
            "Epoch [80/100], Loss: 0.0756\n",
            "Epoch [80/100], Loss: 0.0717\n",
            "Epoch [80/100], Loss: 0.0772\n",
            "Epoch [80/100], Loss: 0.0770\n",
            "Epoch [80/100], Loss: 0.0744\n",
            "Epoch [80/100], Loss: 0.0790\n",
            "Epoch [80/100], Loss: 0.0776\n",
            "Epoch [80/100], Loss: 0.0793\n",
            "Epoch [80/100], Loss: 0.0709\n",
            "Epoch [80/100], Loss: 0.0716\n",
            "Epoch [80/100], Loss: 0.0744\n",
            "Epoch [80/100], Loss: 0.0749\n",
            "Epoch [80/100], Loss: 0.0754\n",
            "Epoch [80/100], Loss: 0.0692\n",
            "Epoch [80/100], Loss: 0.0734\n",
            "Epoch [80/100], Loss: 0.0811\n",
            "Epoch [80/100], Loss: 0.0749\n",
            "Epoch [80/100], Loss: 0.0774\n",
            "Epoch [80/100], Loss: 0.0708\n",
            "Epoch [80/100], Loss: 0.0718\n",
            "Epoch [80/100], Loss: 0.0659\n",
            "Epoch [80/100], Loss: 0.0851\n",
            "Epoch [80/100], Loss: 0.0770\n",
            "Epoch [80/100], Loss: 0.0778\n",
            "Epoch [80/100], Loss: 0.0734\n",
            "Epoch [80/100], Loss: 0.0703\n",
            "Epoch [80/100], Loss: 0.0745\n",
            "Epoch [80/100], Loss: 0.0773\n",
            "Epoch [80/100], Loss: 0.0691\n",
            "Epoch [80/100], Loss: 0.0748\n",
            "Epoch [80/100], Loss: 0.0792\n",
            "Epoch [80/100], Loss: 0.0711\n",
            "Epoch [80/100], Loss: 0.0753\n",
            "Epoch [80/100], Loss: 0.0818\n",
            "Epoch [80/100], Loss: 0.0760\n",
            "Epoch [80/100], Loss: 0.0821\n",
            "Epoch [80/100], Loss: 0.0687\n",
            "Epoch [80/100], Loss: 0.0820\n",
            "Epoch [80/100], Loss: 0.0660\n",
            "Epoch [80/100], Loss: 0.0641\n",
            "Epoch [80/100], Loss: 0.0730\n",
            "Epoch [80/100], Loss: 0.0754\n",
            "Epoch [80/100], Loss: 0.0816\n",
            "Epoch [80/100], Loss: 0.0685\n",
            "Epoch [80/100], Loss: 0.0703\n",
            "Epoch [80/100], Loss: 0.0724\n",
            "Epoch [80/100], Loss: 0.0722\n",
            "Epoch [80/100], Loss: 0.0816\n",
            "Epoch [80/100], Loss: 0.0673\n",
            "Epoch [80/100], Loss: 0.0805\n",
            "Epoch [80/100], Loss: 0.0770\n",
            "Epoch [80/100], Loss: 0.0737\n",
            "Epoch [80/100], Loss: 0.0763\n",
            "Epoch [80/100], Loss: 0.0749\n",
            "Epoch [80/100], Loss: 0.0725\n",
            "Epoch [80/100], Loss: 0.0705\n",
            "Epoch [80/100], Loss: 0.0719\n",
            "Epoch [90/100], Loss: 0.0709\n",
            "Epoch [90/100], Loss: 0.0768\n",
            "Epoch [90/100], Loss: 0.0742\n",
            "Epoch [90/100], Loss: 0.0736\n",
            "Epoch [90/100], Loss: 0.0698\n",
            "Epoch [90/100], Loss: 0.0696\n",
            "Epoch [90/100], Loss: 0.0701\n",
            "Epoch [90/100], Loss: 0.0709\n",
            "Epoch [90/100], Loss: 0.0733\n",
            "Epoch [90/100], Loss: 0.0757\n",
            "Epoch [90/100], Loss: 0.0641\n",
            "Epoch [90/100], Loss: 0.0695\n",
            "Epoch [90/100], Loss: 0.0785\n",
            "Epoch [90/100], Loss: 0.0692\n",
            "Epoch [90/100], Loss: 0.0791\n",
            "Epoch [90/100], Loss: 0.0704\n",
            "Epoch [90/100], Loss: 0.0742\n",
            "Epoch [90/100], Loss: 0.0750\n",
            "Epoch [90/100], Loss: 0.0699\n",
            "Epoch [90/100], Loss: 0.0662\n",
            "Epoch [90/100], Loss: 0.0776\n",
            "Epoch [90/100], Loss: 0.0697\n",
            "Epoch [90/100], Loss: 0.0754\n",
            "Epoch [90/100], Loss: 0.0744\n",
            "Epoch [90/100], Loss: 0.0609\n",
            "Epoch [90/100], Loss: 0.0736\n",
            "Epoch [90/100], Loss: 0.0792\n",
            "Epoch [90/100], Loss: 0.0792\n",
            "Epoch [90/100], Loss: 0.0639\n",
            "Epoch [90/100], Loss: 0.0785\n",
            "Epoch [90/100], Loss: 0.0686\n",
            "Epoch [90/100], Loss: 0.0739\n",
            "Epoch [90/100], Loss: 0.0722\n",
            "Epoch [90/100], Loss: 0.0706\n",
            "Epoch [90/100], Loss: 0.0776\n",
            "Epoch [90/100], Loss: 0.0683\n",
            "Epoch [90/100], Loss: 0.0689\n",
            "Epoch [90/100], Loss: 0.0725\n",
            "Epoch [90/100], Loss: 0.0756\n",
            "Epoch [90/100], Loss: 0.0717\n",
            "Epoch [90/100], Loss: 0.0772\n",
            "Epoch [90/100], Loss: 0.0769\n",
            "Epoch [90/100], Loss: 0.0743\n",
            "Epoch [90/100], Loss: 0.0790\n",
            "Epoch [90/100], Loss: 0.0776\n",
            "Epoch [90/100], Loss: 0.0793\n",
            "Epoch [90/100], Loss: 0.0709\n",
            "Epoch [90/100], Loss: 0.0716\n",
            "Epoch [90/100], Loss: 0.0744\n",
            "Epoch [90/100], Loss: 0.0749\n",
            "Epoch [90/100], Loss: 0.0754\n",
            "Epoch [90/100], Loss: 0.0692\n",
            "Epoch [90/100], Loss: 0.0735\n",
            "Epoch [90/100], Loss: 0.0810\n",
            "Epoch [90/100], Loss: 0.0749\n",
            "Epoch [90/100], Loss: 0.0775\n",
            "Epoch [90/100], Loss: 0.0708\n",
            "Epoch [90/100], Loss: 0.0718\n",
            "Epoch [90/100], Loss: 0.0659\n",
            "Epoch [90/100], Loss: 0.0851\n",
            "Epoch [90/100], Loss: 0.0770\n",
            "Epoch [90/100], Loss: 0.0778\n",
            "Epoch [90/100], Loss: 0.0734\n",
            "Epoch [90/100], Loss: 0.0703\n",
            "Epoch [90/100], Loss: 0.0745\n",
            "Epoch [90/100], Loss: 0.0773\n",
            "Epoch [90/100], Loss: 0.0691\n",
            "Epoch [90/100], Loss: 0.0748\n",
            "Epoch [90/100], Loss: 0.0792\n",
            "Epoch [90/100], Loss: 0.0711\n",
            "Epoch [90/100], Loss: 0.0753\n",
            "Epoch [90/100], Loss: 0.0818\n",
            "Epoch [90/100], Loss: 0.0760\n",
            "Epoch [90/100], Loss: 0.0821\n",
            "Epoch [90/100], Loss: 0.0687\n",
            "Epoch [90/100], Loss: 0.0820\n",
            "Epoch [90/100], Loss: 0.0660\n",
            "Epoch [90/100], Loss: 0.0641\n",
            "Epoch [90/100], Loss: 0.0730\n",
            "Epoch [90/100], Loss: 0.0754\n",
            "Epoch [90/100], Loss: 0.0816\n",
            "Epoch [90/100], Loss: 0.0685\n",
            "Epoch [90/100], Loss: 0.0704\n",
            "Epoch [90/100], Loss: 0.0724\n",
            "Epoch [90/100], Loss: 0.0722\n",
            "Epoch [90/100], Loss: 0.0816\n",
            "Epoch [90/100], Loss: 0.0673\n",
            "Epoch [90/100], Loss: 0.0805\n",
            "Epoch [90/100], Loss: 0.0770\n",
            "Epoch [90/100], Loss: 0.0738\n",
            "Epoch [90/100], Loss: 0.0762\n",
            "Epoch [90/100], Loss: 0.0748\n",
            "Epoch [90/100], Loss: 0.0725\n",
            "Epoch [90/100], Loss: 0.0705\n",
            "Epoch [90/100], Loss: 0.0719\n",
            "Epoch [100/100], Loss: 0.0709\n",
            "Epoch [100/100], Loss: 0.0769\n",
            "Epoch [100/100], Loss: 0.0742\n",
            "Epoch [100/100], Loss: 0.0736\n",
            "Epoch [100/100], Loss: 0.0697\n",
            "Epoch [100/100], Loss: 0.0696\n",
            "Epoch [100/100], Loss: 0.0700\n",
            "Epoch [100/100], Loss: 0.0709\n",
            "Epoch [100/100], Loss: 0.0734\n",
            "Epoch [100/100], Loss: 0.0757\n",
            "Epoch [100/100], Loss: 0.0641\n",
            "Epoch [100/100], Loss: 0.0695\n",
            "Epoch [100/100], Loss: 0.0785\n",
            "Epoch [100/100], Loss: 0.0692\n",
            "Epoch [100/100], Loss: 0.0792\n",
            "Epoch [100/100], Loss: 0.0704\n",
            "Epoch [100/100], Loss: 0.0742\n",
            "Epoch [100/100], Loss: 0.0750\n",
            "Epoch [100/100], Loss: 0.0699\n",
            "Epoch [100/100], Loss: 0.0662\n",
            "Epoch [100/100], Loss: 0.0776\n",
            "Epoch [100/100], Loss: 0.0697\n",
            "Epoch [100/100], Loss: 0.0753\n",
            "Epoch [100/100], Loss: 0.0744\n",
            "Epoch [100/100], Loss: 0.0609\n",
            "Epoch [100/100], Loss: 0.0736\n",
            "Epoch [100/100], Loss: 0.0792\n",
            "Epoch [100/100], Loss: 0.0792\n",
            "Epoch [100/100], Loss: 0.0640\n",
            "Epoch [100/100], Loss: 0.0786\n",
            "Epoch [100/100], Loss: 0.0685\n",
            "Epoch [100/100], Loss: 0.0739\n",
            "Epoch [100/100], Loss: 0.0723\n",
            "Epoch [100/100], Loss: 0.0706\n",
            "Epoch [100/100], Loss: 0.0776\n",
            "Epoch [100/100], Loss: 0.0683\n",
            "Epoch [100/100], Loss: 0.0689\n",
            "Epoch [100/100], Loss: 0.0725\n",
            "Epoch [100/100], Loss: 0.0756\n",
            "Epoch [100/100], Loss: 0.0717\n",
            "Epoch [100/100], Loss: 0.0772\n",
            "Epoch [100/100], Loss: 0.0770\n",
            "Epoch [100/100], Loss: 0.0744\n",
            "Epoch [100/100], Loss: 0.0790\n",
            "Epoch [100/100], Loss: 0.0776\n",
            "Epoch [100/100], Loss: 0.0793\n",
            "Epoch [100/100], Loss: 0.0709\n",
            "Epoch [100/100], Loss: 0.0716\n",
            "Epoch [100/100], Loss: 0.0743\n",
            "Epoch [100/100], Loss: 0.0749\n",
            "Epoch [100/100], Loss: 0.0754\n",
            "Epoch [100/100], Loss: 0.0692\n",
            "Epoch [100/100], Loss: 0.0734\n",
            "Epoch [100/100], Loss: 0.0810\n",
            "Epoch [100/100], Loss: 0.0749\n",
            "Epoch [100/100], Loss: 0.0774\n",
            "Epoch [100/100], Loss: 0.0709\n",
            "Epoch [100/100], Loss: 0.0718\n",
            "Epoch [100/100], Loss: 0.0658\n",
            "Epoch [100/100], Loss: 0.0851\n",
            "Epoch [100/100], Loss: 0.0769\n",
            "Epoch [100/100], Loss: 0.0778\n",
            "Epoch [100/100], Loss: 0.0734\n",
            "Epoch [100/100], Loss: 0.0703\n",
            "Epoch [100/100], Loss: 0.0745\n",
            "Epoch [100/100], Loss: 0.0772\n",
            "Epoch [100/100], Loss: 0.0691\n",
            "Epoch [100/100], Loss: 0.0748\n",
            "Epoch [100/100], Loss: 0.0793\n",
            "Epoch [100/100], Loss: 0.0711\n",
            "Epoch [100/100], Loss: 0.0753\n",
            "Epoch [100/100], Loss: 0.0818\n",
            "Epoch [100/100], Loss: 0.0759\n",
            "Epoch [100/100], Loss: 0.0820\n",
            "Epoch [100/100], Loss: 0.0687\n",
            "Epoch [100/100], Loss: 0.0820\n",
            "Epoch [100/100], Loss: 0.0660\n",
            "Epoch [100/100], Loss: 0.0642\n",
            "Epoch [100/100], Loss: 0.0730\n",
            "Epoch [100/100], Loss: 0.0754\n",
            "Epoch [100/100], Loss: 0.0817\n",
            "Epoch [100/100], Loss: 0.0685\n",
            "Epoch [100/100], Loss: 0.0703\n",
            "Epoch [100/100], Loss: 0.0723\n",
            "Epoch [100/100], Loss: 0.0721\n",
            "Epoch [100/100], Loss: 0.0816\n",
            "Epoch [100/100], Loss: 0.0673\n",
            "Epoch [100/100], Loss: 0.0805\n",
            "Epoch [100/100], Loss: 0.0771\n",
            "Epoch [100/100], Loss: 0.0738\n",
            "Epoch [100/100], Loss: 0.0763\n",
            "Epoch [100/100], Loss: 0.0749\n",
            "Epoch [100/100], Loss: 0.0726\n",
            "Epoch [100/100], Loss: 0.0705\n",
            "Epoch [100/100], Loss: 0.0718\n"
          ]
        }
      ],
      "source": [
        "# Train autoencoder\n",
        "input_dim = X_train.shape[1]\n",
        "encoded_dim = 4\n",
        "autoencoder = Autoencoder(input_dim, encoded_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.01)\n",
        "num_epochs = 100\n",
        "noise_factor= 0.3\n",
        "num_workers = 0\n",
        "traindata = torch.FloatTensor(X_train)\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(traindata, batch_size=10, num_workers=10)\n",
        "k= []\n",
        "for epoch in range(num_epochs):\n",
        "  for data in train_loader:\n",
        "    inputs = data\n",
        "    noisy_inputs = inputs + noise_factor * torch.randn(*inputs.shape)\n",
        "    # Clip the images to be between 0 and 1\n",
        "    #noisy_inputs = np.clip(noisy_inputs, 0., 1.)\n",
        "    encoded, decoded = autoencoder(noisy_inputs)\n",
        "    loss = criterion(decoded, inputs)\n",
        "    l1_weight = 0.001\n",
        "    l2_weight = 0.001\n",
        "    parameters = []\n",
        "    for parameter in autoencoder.parameters():\n",
        "        parameters.append(parameter.view(-1))\n",
        "    l1 = l1_weight * autoencoder.compute_l1_loss(torch.cat(parameters))\n",
        "    l2 = l2_weight * autoencoder.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "    loss += l1\n",
        "    loss += l2\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs,\n",
        "                                                  loss.item()))\n",
        "  k.append(loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbBFHNW459Xa"
      },
      "source": [
        "### MSE of Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HSy6MQ_Fxv2e"
      },
      "outputs": [],
      "source": [
        "#print(\"MSE of Autoencoder\",np.mean(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TH6TSXJJeEBC"
      },
      "outputs": [],
      "source": [
        "# encoded_features, _ = autoencoder(torch.from_numpy(X_train).float())\n",
        "# encoded_features = encoded_features.detach().numpy()\n",
        "# encoded_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5xC6p8hcpQl"
      },
      "source": [
        "### Save features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkVKhjHcfIMt",
        "outputId": "93d497a0-fafc-4e65-d5cd-17e56e53a5cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "PATH = 'models/autoencoder.pt'\n",
        "torch.save(autoencoder.encoder, PATH)\n",
        "# PATH_BEST = 'models/autoencoder_best.pt'\n",
        "# encoder = torch.load('models/autoencoder_best.pt')\n",
        "encoder = torch.load('models/autoencoder.pt')\n",
        "with torch.no_grad():\n",
        "    encoded_features, _ = autoencoder(torch.from_numpy(X_train).float())\n",
        "encoded_features = encoded_features.detach().numpy()\n",
        "encoded_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5gxQMOT4fQse"
      },
      "outputs": [],
      "source": [
        "# Save encoded features to file\n",
        "encoded_features_df = pd.DataFrame(encoded_features)\n",
        "encoded_features_df.to_pickle('data/encoded_features/encoded_features.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqI05TkR6v8B"
      },
      "source": [
        "## 7. KMeans clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dh7zSDreRxNS",
        "outputId": "e2cfe901-608f-4c50-837f-10d1199dda88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Determine the number of clusters\n",
        "elbow = []\n",
        "for i in range(1, 50):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=0).fit(encoded_features)\n",
        "    elbow.append(kmeans.inertia_)\n",
        "\n",
        "# Plot elbow curve to determine the optimal number of clusters\n",
        "plt.plot(range(1, 50), elbow)\n",
        "plt.title('Elbow Curve')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YWvVOLnSR4sT"
      },
      "outputs": [],
      "source": [
        "n_clusters = 7\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10).fit(encoded_features)\n",
        "cluster_labels = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mjK49YLcR7nF",
        "outputId": "18fc934f-2081-4aa5-e933-24517a319de5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cluster0  cluster1  cluster2  cluster3  cluster4  cluster5  cluster6\n",
              "1         0.0       0.0       0.0       0.0       0.0       0.0       1.0\n",
              "2         0.0       0.0       1.0       0.0       0.0       0.0       0.0\n",
              "3         0.0       0.0       0.0       0.0       0.0       1.0       0.0\n",
              "4         0.0       0.0       0.0       0.0       0.0       0.0       1.0\n",
              "5         1.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "..        ...       ...       ...       ...       ...       ...       ...\n",
              "939       0.0       0.0       0.0       0.0       0.0       1.0       0.0\n",
              "940       1.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "941       0.0       0.0       0.0       0.0       1.0       0.0       0.0\n",
              "942       1.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "943       1.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "\n",
              "[943 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7ba91f7-0e15-4fea-9ca0-827efd4e4045\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster0</th>\n",
              "      <th>cluster1</th>\n",
              "      <th>cluster2</th>\n",
              "      <th>cluster3</th>\n",
              "      <th>cluster4</th>\n",
              "      <th>cluster5</th>\n",
              "      <th>cluster6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7ba91f7-0e15-4fea-9ca0-827efd4e4045')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7ba91f7-0e15-4fea-9ca0-827efd4e4045 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7ba91f7-0e15-4fea-9ca0-827efd4e4045');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#Create user-cluster mattrix\n",
        "Cluster = ['cluster0', 'cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5', 'cluster6']\n",
        "df1 = pd.DataFrame(np.zeros((943,7)), columns=Cluster)\n",
        "df1.index = df1.index + 1\n",
        "UID = 1\n",
        "for i in cluster_labels:\n",
        "  df1.loc[UID][i] = 1\n",
        "  UID = UID + 1\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5574KMWIoDpm"
      },
      "outputs": [],
      "source": [
        "dataPath = 'datasets/ml-100k/'\n",
        "df_read = pd.read_csv(dataPath+'u1.base', sep='\\\\t', engine='python', names=['UID', 'MID', 'rate', 'time'])\n",
        "df_read = df_read.drop(['time'], axis = 1)\n",
        "df_read = df_read.pivot(index = 'UID', columns = 'MID', values = 'rate')\n",
        "df = pd.DataFrame(0, columns=list(range(1,1683)), index=list(range(1,944)))\n",
        "df = df.combine(df_read, np.maximum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "ruj-TKnQSMfz",
        "outputId": "d2b3499c-ae11-4c3c-e41c-446b607644d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         1    2    3    4    5    6    7    8    9    10    ... 1673 1674  \\\n",
              "cluster0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster6  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "\n",
              "         1675 1676 1677 1678 1679 1680 1681 1682  \n",
              "cluster0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster6  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "\n",
              "[7 rows x 1682 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c693e40-adf6-4a6e-bdfd-0e5735303314\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cluster0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c693e40-adf6-4a6e-bdfd-0e5735303314')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c693e40-adf6-4a6e-bdfd-0e5735303314 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c693e40-adf6-4a6e-bdfd-0e5735303314');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df2 = pd.DataFrame(index = Cluster, columns=list(range(1,1683)))\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "M8CPkIkbSUD3"
      },
      "outputs": [],
      "source": [
        "def find_similar_movie(cluster_rate, mid, df_item):\n",
        "    similar_Movies = []\n",
        "    genres = df_item[mid-1]\n",
        "    for Movies in cluster_rate.index:\n",
        "        comp_genres = df_item[Movies - 1]\n",
        "        if np.array_equal(genres, comp_genres) and Movies != mid:\n",
        "            similar_Movies.append(Movies)\n",
        "    return similar_Movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RJJ8IKVeSarD"
      },
      "outputs": [],
      "source": [
        "def check_user_exist(Movies, users, df):\n",
        "  if df.loc[users][Movies].isnull().all().all() == False:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52whc8vmd-LE"
      },
      "source": [
        "## 9. Predict Cluster's rating movies in df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4zILbdruSeKy"
      },
      "outputs": [],
      "source": [
        "dataPath = 'datasets/ml-100k/'\n",
        "df_item = pd.read_csv(dataPath + 'u.item', sep='\\\\|', engine='python',\n",
        "                      names=['MID', 'title', 'rdate', 'vdate', 'URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "                              'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
        "                              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
        "                              'Western'], encoding='latin-1')\n",
        "df_item = df_item[df_item.columns[5:]]\n",
        "df_item = np.array(df_item)\n",
        "\n",
        "for Movie in df2.columns:\n",
        "  for cluster in Cluster:\n",
        "    user = df1.index[df1[cluster] == 1]\n",
        "    if df.loc[user][Movie].isnull().all().all() == False:\n",
        "        df2.loc[cluster][Movie] = np.nanmean(df.loc[user][Movie])\n",
        "        # df2.loc[cluster][Movie] = df.loc[user][Movie].mode()\n",
        "        continue\n",
        "    # else :\n",
        "    #     df2.loc[cluster][Movie] = np.nanmean(df.loc[df.index][Movie])\n",
        "    S_M = find_similar_movie(df2.loc[cluster], Movie, df_item)\n",
        "    if check_user_exist(S_M, user, df) == True:\n",
        "        df2.loc[cluster][Movie] = np.nanmean(df.loc[user][S_M])\n",
        "    else:\n",
        "        df2.loc[cluster][Movie] = np.nanmean(df.loc[user])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "1mn9aJrJeAKA",
        "outputId": "d22b2c9c-dec9-42e5-a097-ab90dc4a3b8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f5f21a3f-a541-4685-8957-6088a4e846d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cluster0</th>\n",
              "      <td>3.759494</td>\n",
              "      <td>3.185185</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.404255</td>\n",
              "      <td>3.235294</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>3.772152</td>\n",
              "      <td>3.978261</td>\n",
              "      <td>3.640625</td>\n",
              "      <td>3.5</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>3.606</td>\n",
              "      <td>3.229073</td>\n",
              "      <td>3.681209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster1</th>\n",
              "      <td>3.891304</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>2.625</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.454545</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.676471</td>\n",
              "      <td>4.125</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>4.4</td>\n",
              "      <td>...</td>\n",
              "      <td>3.404332</td>\n",
              "      <td>3.550041</td>\n",
              "      <td>3.550041</td>\n",
              "      <td>3.550041</td>\n",
              "      <td>3.550041</td>\n",
              "      <td>3.550041</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.672655</td>\n",
              "      <td>3.31058</td>\n",
              "      <td>3.550041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster2</th>\n",
              "      <td>3.893617</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.416667</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>3.3</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.918919</td>\n",
              "      <td>3.941176</td>\n",
              "      <td>4.357143</td>\n",
              "      <td>3.777778</td>\n",
              "      <td>...</td>\n",
              "      <td>3.398417</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.52381</td>\n",
              "      <td>3.665988</td>\n",
              "      <td>3.380412</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>3.529412</td>\n",
              "      <td>3.285714</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.72093</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>4.2</td>\n",
              "      <td>...</td>\n",
              "      <td>3.463612</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.762943</td>\n",
              "      <td>3.762943</td>\n",
              "      <td>3.762943</td>\n",
              "      <td>3.762943</td>\n",
              "      <td>3.538462</td>\n",
              "      <td>3.625743</td>\n",
              "      <td>3.291099</td>\n",
              "      <td>3.762943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster4</th>\n",
              "      <td>3.702128</td>\n",
              "      <td>3.384615</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.8125</td>\n",
              "      <td>3.090909</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.176471</td>\n",
              "      <td>3.772727</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>...</td>\n",
              "      <td>3.481481</td>\n",
              "      <td>3.667456</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.667456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.123256</td>\n",
              "      <td>3.667456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster5</th>\n",
              "      <td>3.983333</td>\n",
              "      <td>3.125</td>\n",
              "      <td>2.363636</td>\n",
              "      <td>3.681818</td>\n",
              "      <td>3.444444</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.756098</td>\n",
              "      <td>4.074074</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.436275</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.181818</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.643001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster6</th>\n",
              "      <td>4.066667</td>\n",
              "      <td>3.166667</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>3.24</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.882353</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>3.379085</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.580556</td>\n",
              "      <td>3.245742</td>\n",
              "      <td>3.626471</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5f21a3f-a541-4685-8957-6088a4e846d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5f21a3f-a541-4685-8957-6088a4e846d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5f21a3f-a541-4685-8957-6088a4e846d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              1         2         3         4         5         6     \\\n",
              "cluster0  3.759494  3.185185  2.666667  3.404255  3.235294  3.571429   \n",
              "cluster1  3.891304  3.285714     2.625       3.4  3.454545       3.0   \n",
              "cluster2  3.893617       3.0  3.416667  3.833333       3.3  3.666667   \n",
              "cluster3       4.0       3.2  2.833333  3.529412  3.285714       4.5   \n",
              "cluster4  3.702128  3.384615       3.5    3.8125  3.090909  3.666667   \n",
              "cluster5  3.983333     3.125  2.363636  3.681818  3.444444       2.0   \n",
              "cluster6  4.066667  3.166667  3.833333      3.24       3.5       2.5   \n",
              "\n",
              "              7         8         9         10    ...      1673      1674  \\\n",
              "cluster0  3.772152  3.978261  3.640625       3.5  ...       3.0  3.681209   \n",
              "cluster1  3.676471     4.125  3.833333       4.4  ...  3.404332  3.550041   \n",
              "cluster2  3.918919  3.941176  4.357143  3.777778  ...  3.398417  3.788618   \n",
              "cluster3   3.72093       3.8       3.7       4.2  ...  3.463612       4.0   \n",
              "cluster4       3.8  4.176471  3.772727  3.857143  ...  3.481481  3.667456   \n",
              "cluster5  3.756098  4.074074  3.636364       4.0  ...  3.436275  3.643001   \n",
              "cluster6       4.0  3.882353      3.92  3.571429  ...  3.379085  3.626471   \n",
              "\n",
              "              1675      1676      1677      1678      1679      1680  \\\n",
              "cluster0  3.681209  3.681209  3.681209  3.681209  3.928571     3.606   \n",
              "cluster1  3.550041  3.550041  3.550041  3.550041       3.5  3.672655   \n",
              "cluster2  3.788618  3.788618  3.788618  3.788618   3.52381  3.665988   \n",
              "cluster3  3.762943  3.762943  3.762943  3.762943  3.538462  3.625743   \n",
              "cluster4       3.0       2.0  3.667456       1.0       3.0       2.0   \n",
              "cluster5  3.643001  3.643001       3.0  3.643001  3.181818  3.666667   \n",
              "cluster6  3.626471  3.626471  3.626471  3.626471       3.5  3.580556   \n",
              "\n",
              "              1681      1682  \n",
              "cluster0  3.229073  3.681209  \n",
              "cluster1   3.31058  3.550041  \n",
              "cluster2  3.380412       3.0  \n",
              "cluster3  3.291099  3.762943  \n",
              "cluster4  3.123256  3.667456  \n",
              "cluster5       3.0  3.643001  \n",
              "cluster6  3.245742  3.626471  \n",
              "\n",
              "[7 rows x 1682 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjBgwBHW-VQk"
      },
      "source": [
        "## 10. Predict User's rating for all movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "wZkLWgYN0csA",
        "outputId": "5faac016-e0fe-4153-a9b6-265f225cb2e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1451b9e1-8f3f-4f88-8a83-3b4f4eb4d4d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.066667</td>\n",
              "      <td>3.166667</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>3.24</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.882353</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>3.379085</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.580556</td>\n",
              "      <td>3.245742</td>\n",
              "      <td>3.626471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.893617</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.416667</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>3.3</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.918919</td>\n",
              "      <td>3.941176</td>\n",
              "      <td>4.357143</td>\n",
              "      <td>3.777778</td>\n",
              "      <td>...</td>\n",
              "      <td>3.398417</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.788618</td>\n",
              "      <td>3.52381</td>\n",
              "      <td>3.665988</td>\n",
              "      <td>3.380412</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.983333</td>\n",
              "      <td>3.125</td>\n",
              "      <td>2.363636</td>\n",
              "      <td>3.681818</td>\n",
              "      <td>3.444444</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.756098</td>\n",
              "      <td>4.074074</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.436275</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.181818</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.643001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.066667</td>\n",
              "      <td>3.166667</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>3.24</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.882353</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>3.379085</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.626471</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.580556</td>\n",
              "      <td>3.245742</td>\n",
              "      <td>3.626471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.759494</td>\n",
              "      <td>3.185185</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.404255</td>\n",
              "      <td>3.235294</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>3.772152</td>\n",
              "      <td>3.978261</td>\n",
              "      <td>3.640625</td>\n",
              "      <td>3.5</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>3.606</td>\n",
              "      <td>3.229073</td>\n",
              "      <td>3.681209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>3.983333</td>\n",
              "      <td>3.125</td>\n",
              "      <td>2.363636</td>\n",
              "      <td>3.681818</td>\n",
              "      <td>3.444444</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.756098</td>\n",
              "      <td>4.074074</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.436275</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.643001</td>\n",
              "      <td>3.181818</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.643001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>3.759494</td>\n",
              "      <td>3.185185</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.404255</td>\n",
              "      <td>3.235294</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>3.772152</td>\n",
              "      <td>3.978261</td>\n",
              "      <td>3.640625</td>\n",
              "      <td>3.5</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>3.606</td>\n",
              "      <td>3.229073</td>\n",
              "      <td>3.681209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>3.702128</td>\n",
              "      <td>3.384615</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.8125</td>\n",
              "      <td>3.090909</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.176471</td>\n",
              "      <td>3.772727</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>...</td>\n",
              "      <td>3.481481</td>\n",
              "      <td>3.667456</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.667456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.123256</td>\n",
              "      <td>3.667456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>3.759494</td>\n",
              "      <td>3.185185</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.404255</td>\n",
              "      <td>3.235294</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>3.772152</td>\n",
              "      <td>3.978261</td>\n",
              "      <td>3.640625</td>\n",
              "      <td>3.5</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>3.606</td>\n",
              "      <td>3.229073</td>\n",
              "      <td>3.681209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>3.759494</td>\n",
              "      <td>3.185185</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.404255</td>\n",
              "      <td>3.235294</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>3.772152</td>\n",
              "      <td>3.978261</td>\n",
              "      <td>3.640625</td>\n",
              "      <td>3.5</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.681209</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>3.606</td>\n",
              "      <td>3.229073</td>\n",
              "      <td>3.681209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1451b9e1-8f3f-4f88-8a83-3b4f4eb4d4d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1451b9e1-8f3f-4f88-8a83-3b4f4eb4d4d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1451b9e1-8f3f-4f88-8a83-3b4f4eb4d4d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         1         2         3         4         5         6         7     \\\n",
              "1    4.066667  3.166667  3.833333      3.24       3.5       2.5       4.0   \n",
              "2    3.893617       3.0  3.416667  3.833333       3.3  3.666667  3.918919   \n",
              "3    3.983333     3.125  2.363636  3.681818  3.444444       2.0  3.756098   \n",
              "4    4.066667  3.166667  3.833333      3.24       3.5       2.5       4.0   \n",
              "5    3.759494  3.185185  2.666667  3.404255  3.235294  3.571429  3.772152   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "939  3.983333     3.125  2.363636  3.681818  3.444444       2.0  3.756098   \n",
              "940  3.759494  3.185185  2.666667  3.404255  3.235294  3.571429  3.772152   \n",
              "941  3.702128  3.384615       3.5    3.8125  3.090909  3.666667       3.8   \n",
              "942  3.759494  3.185185  2.666667  3.404255  3.235294  3.571429  3.772152   \n",
              "943  3.759494  3.185185  2.666667  3.404255  3.235294  3.571429  3.772152   \n",
              "\n",
              "         8         9         10    ...      1673      1674      1675  \\\n",
              "1    3.882353      3.92  3.571429  ...  3.379085  3.626471  3.626471   \n",
              "2    3.941176  4.357143  3.777778  ...  3.398417  3.788618  3.788618   \n",
              "3    4.074074  3.636364       4.0  ...  3.436275  3.643001  3.643001   \n",
              "4    3.882353      3.92  3.571429  ...  3.379085  3.626471  3.626471   \n",
              "5    3.978261  3.640625       3.5  ...       3.0  3.681209  3.681209   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "939  4.074074  3.636364       4.0  ...  3.436275  3.643001  3.643001   \n",
              "940  3.978261  3.640625       3.5  ...       3.0  3.681209  3.681209   \n",
              "941  4.176471  3.772727  3.857143  ...  3.481481  3.667456       3.0   \n",
              "942  3.978261  3.640625       3.5  ...       3.0  3.681209  3.681209   \n",
              "943  3.978261  3.640625       3.5  ...       3.0  3.681209  3.681209   \n",
              "\n",
              "         1676      1677      1678      1679      1680      1681      1682  \n",
              "1    3.626471  3.626471  3.626471       3.5  3.580556  3.245742  3.626471  \n",
              "2    3.788618  3.788618  3.788618   3.52381  3.665988  3.380412       3.0  \n",
              "3    3.643001       3.0  3.643001  3.181818  3.666667       3.0  3.643001  \n",
              "4    3.626471  3.626471  3.626471       3.5  3.580556  3.245742  3.626471  \n",
              "5    3.681209  3.681209  3.681209  3.928571     3.606  3.229073  3.681209  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "939  3.643001       3.0  3.643001  3.181818  3.666667       3.0  3.643001  \n",
              "940  3.681209  3.681209  3.681209  3.928571     3.606  3.229073  3.681209  \n",
              "941       2.0  3.667456       1.0       3.0       2.0  3.123256  3.667456  \n",
              "942  3.681209  3.681209  3.681209  3.928571     3.606  3.229073  3.681209  \n",
              "943  3.681209  3.681209  3.681209  3.928571     3.606  3.229073  3.681209  \n",
              "\n",
              "[943 rows x 1682 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# np.dot(df1, df2)\n",
        "prediction = df1.dot(df2)\n",
        "#df2.dot(df1)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NezjNqrkfr46"
      },
      "source": [
        "## 11. Root Mean Square Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "WN6CqW7hfPmp",
        "outputId": "72922432-57c3-4098-ad51-2b293ae9a691"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cdda2e6f-cf32-4b1d-8852-a08afc7a0c4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>MID</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1555</th>\n",
              "      <th>1557</th>\n",
              "      <th>1561</th>\n",
              "      <th>1562</th>\n",
              "      <th>1563</th>\n",
              "      <th>1565</th>\n",
              "      <th>1578</th>\n",
              "      <th>1582</th>\n",
              "      <th>1586</th>\n",
              "      <th>1591</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>459 rows × 1410 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdda2e6f-cf32-4b1d-8852-a08afc7a0c4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdda2e6f-cf32-4b1d-8852-a08afc7a0c4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdda2e6f-cf32-4b1d-8852-a08afc7a0c4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "MID  1     2     3     4     5     6     7     8     9     10    ...  1555  \\\n",
              "UID                                                              ...         \n",
              "1     NaN   NaN   NaN   NaN   NaN   5.0   NaN   NaN   NaN   3.0  ...   NaN   \n",
              "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "5     4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "457   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "458   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "459   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "460   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   3.0  ...   NaN   \n",
              "462   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "\n",
              "MID  1557  1561  1562  1563  1565  1578  1582  1586  1591  \n",
              "UID                                                        \n",
              "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "5     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "457   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "458   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "459   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "460   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "462   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "\n",
              "[459 rows x 1410 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataPath = 'datasets/ml-100k/'\n",
        "df_test = pd.read_csv(dataPath+'u1.test', sep='\\\\t', engine='python', names=['UID', 'MID', 'rate', 'time'])\n",
        "df_test = df_test.drop(['time'], axis = 1)\n",
        "df_test = df_test.pivot(index = 'UID', columns = 'MID', values = 'rate')\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW-urhAa0fPF",
        "outputId": "844a8fb3-773c-4c01-a54d-01bf5e48cbef"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE of Hybrid approach for movies recommendation based on Graph and Autoencoder: 1.083535444196354\n"
          ]
        }
      ],
      "source": [
        "RMSE = np.sqrt(np.nanmean(np.square(df_test - prediction)))\n",
        "print(\"RMSE of Hybrid approach for movies recommendation based on Graph and Autoencoder:\",RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tSlnPhr2DiK"
      },
      "source": [
        "## 12.Precision and Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "OHtANzcB7hCN"
      },
      "outputs": [],
      "source": [
        "#Define Precision and Recall\n",
        "def Precision_Recall(user, df_True, df_Predict, top_N):\n",
        "  TP = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "\n",
        "  top_n_recommendations = prediction.loc[user].sort_values(ascending=False).head(top_N)\n",
        "  if len(top_n_recommendations) == 0:\n",
        "    return(1, 1)\n",
        "  for movie in df_True.columns :\n",
        "    if df_True.loc[user][movie] >= 4:\n",
        "      if movie in top_n_recommendations.index :\n",
        "        TP += 1\n",
        "      else:\n",
        "        FN += 1\n",
        "    elif df_True.loc[user][movie] < 4:\n",
        "      if movie in top_n_recommendations.index :\n",
        "        FP += 1\n",
        "    else:\n",
        "      continue\n",
        "  if TP == 0:\n",
        "    return (0, 0)\n",
        "  precision = TP/(TP + FP)\n",
        "  recall = TP/(TP + FN)\n",
        "  return(precision, recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "out4iT8M0lGG",
        "outputId": "f0368ac2-8b92-424a-94f2-ae3c7991e564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision 0.6682834154924848\n",
            "Recall: 0.7187738507510105\n"
          ]
        }
      ],
      "source": [
        "predictions = prediction - df_test + df_test\n",
        "Precision = []\n",
        "Recall = []\n",
        "\n",
        "for user in df_test.index:\n",
        "  pre, re = Precision_Recall(user, df_test, predictions, 20)\n",
        "  Precision.append(pre)\n",
        "  Recall.append(re)\n",
        "print(\"Precision\", np.mean(Precision))\n",
        "print(\"Recall:\", np.mean(Recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. In ra những bộ phim gợi ý cho người xem"
      ],
      "metadata": {
        "id": "oVgRhjoaLJZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UID = 200\n",
        "top_N = 20\n",
        "MovieRecommend = prediction.loc[940].sort_values(ascending=False).head(top_N).index.values\n",
        "# load the u.item file\n",
        "df_item = pd.read_csv(dataPath + 'u.item', sep='\\\\|', engine='python',\n",
        "                      names=['MID', 'title', 'rdate', 'vdate', 'URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "                              'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
        "                              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
        "                              'Western'], encoding='latin-1')\n",
        "for mid in MovieRecommend:\n",
        "    movie_name = df_item.loc[df_item['MID'] == mid]['title'].values[0]\n",
        "    print(movie_name)\n"
      ],
      "metadata": {
        "id": "6e0joRdYLINx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c2e6cc-78a3-4668-efb1-565c3d99f2ee"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toy Story (1995)\n",
            "GoldenEye (1995)\n",
            "Four Rooms (1995)\n",
            "Get Shorty (1995)\n",
            "Copycat (1995)\n",
            "Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)\n",
            "Twelve Monkeys (1995)\n",
            "Babe (1995)\n",
            "Dead Man Walking (1995)\n",
            "Richard III (1995)\n",
            "Seven (Se7en) (1995)\n",
            "Usual Suspects, The (1995)\n",
            "Mighty Aphrodite (1995)\n",
            "Postino, Il (1994)\n",
            "Mr. Holland's Opus (1995)\n",
            "French Twist (Gazon maudit) (1995)\n",
            "From Dusk Till Dawn (1996)\n",
            "White Balloon, The (1995)\n",
            "Antonia's Line (1995)\n",
            "Angels and Insects (1995)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}